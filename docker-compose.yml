version: '3.8'

services:
  # 1. Ingesta (Se mantiene igual)
  ingestion-service:
    build: ./ingest
    ports:
      - "8000:8000"
      - "9999:9999"
    env_file:
      - ./ingest/.env
    environment:
      - OCR_ENDPOINT=http://localhost:9999/ocr
      - OCR_ENGINE_NAME=rapidocr
    volumes:
      - ./ingest:/app

  # 2. Base de Datos (Se mantiene igual)
  neo4j-db:
    image: neo4j:5.15
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/prismafinance123
      - NEO4J_PLUGINS=["apoc"]
    volumes:
      - neo4j_data:/data

  # 3. LLM Local (COMENTADO - Usamos el del otro PC para ahorrar recursos)
  # ollama-service:
  #   image: ollama/ollama:latest
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_storage:/root/.ollama

  # 4. Agente (Consumidor Remoto)
  graph-agent:
      build: ./Agent
      ports:
        - "8081:8081"
      depends_on:
        - ingestion-service
        - neo4j-db
        # - ollama-service  <-- Ya no depende del local
      environment:
        - NEO4J_URI=bolt://neo4j-db:7687
        - NEO4J_USERNAME=neo4j
        - NEO4J_PASSWORD=prismafinance123
        - INGESTION_URL=http://ingestion-service:8000
        
        # --- CONEXIÓN REMOTA ---
        # Apuntamos a la IP del otro PC
        - OPENAI_API_BASE=http://192.168.50.1:8900/v1
        - OLLAMA_BASE_URL=http://192.168.50.1:8900/v1
        - OPENAI_API_KEY=sk-no-key-needed
        
        # --- MODELO ESPECÍFICO ---
        # Aquí definimos el nombre exacto que tiene el servidor
        - LLM_MODEL_ID=unsloth/qwen3-4b-instruct-2507
      
      volumes:
        - ./Documentos_Recibidos:/app/backups

  # 5. Servicio MCP (Se mantiene igual)
  neo4j-mcp:
    build: ./MCP
    ports:
      - "8082:8082"
    depends_on:
      - neo4j-db
    environment:
      - NEO4J_URI=bolt://neo4j-db:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=prismafinance123
      - MCP_NEO4J_MODE=READ_WRITE

volumes:
  neo4j_data:
  ollama_storage: